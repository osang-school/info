package osangdata

import (
	"fmt"
	"log"
	"net/http"
	"time"

	"github.com/PuerkitoBio/goquery"
)

type Url string

const (
	baseUrl           Url = "http://school.gyo6.net/osangms"
	UrlNotice             = baseUrl + "/0301/board/70879"
	UrlPrints             = baseUrl + "/0302/board/70880"
	UrlRule               = baseUrl + "/020301/board/70875"
	UrlEvaluationPlan     = baseUrl + "/141482/board/70873"
	UrlAdministration     = baseUrl + "/0303/board/70881"
)

type List struct {
	ID        int
	Number    uint
	Title     string
	WrittenBy string
	CreateAt  time.Time
}

func CrawlList(url Url) error {
	res, err := http.Get(string(url))
	if err != nil {
		log.Fatal(err)
	}
	defer res.Body.Close()
	if res.StatusCode != 200 {
		return fmt.Errorf("Error Loading")
	}

	doc, err := goquery.NewDocumentFromReader(res.Body)
	if err != nil {
		log.Fatal(err)
	}

	fmt.Println("Start Crawl")
	doc.Find("table tbody tr").Each(func(i int, s *goquery.Selection) {
		if href, err := s.Find("a").Attr("href"); href != "#contents" {
			return
		}
		fmt.Println(s.Find("a").Attr("title"))
	})
	fmt.Println("End Crawl")
	return nil
}
